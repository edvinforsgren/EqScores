{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utilities as ut\n",
    "import plotly.express as px\n",
    "import pyPLS\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_feat_path = \"./data/2020_11_04_CPJUMP1_normalized_feature_select_negcon_batch_Standard.parquet.gz\"\n",
    "df = pd.read_parquet(cp_feat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = ut.get_featuredata(df).shape\n",
    "ar = np.random.rand(row, col)\n",
    "rand_df = pd.concat([ut.get_metadata(df), pd.DataFrame(data=ar)], axis=1)\n",
    "rand_df.columns = rand_df.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 100\n",
    "pca = PCA(n_components=n_components)\n",
    "X = pca.fit_transform(ut.get_featuredata(rand_df).values.astype(float))\n",
    "rand_pca_df = ut.get_metadata(df).copy()\n",
    "for i in range(n_components):\n",
    "    rand_pca_df[f'T{i+1}'] = X[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_pca_df.to_parquet('./data/rand_pca_df.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 100\n",
    "pca = PCA(n_components=n_components)\n",
    "X = pca.fit_transform(ut.get_featuredata(df).values.astype(float))\n",
    "pca_df = ut.get_metadata(df).copy()\n",
    "for i in range(n_components):\n",
    "    pca_df[f'T{i+1}'] = X[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df.to_parquet('./data/pca_df.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound A549 48\n",
      "Compound A549 24\n",
      "Compound U2OS 24\n",
      "Compound U2OS 48\n",
      "ORF A549 48\n",
      "ORF A549 96\n",
      "ORF U2OS 48\n",
      "ORF U2OS 96\n",
      "CRISPR A549 144\n",
      "CRISPR A549 96\n",
      "CRISPR U2OS 144\n",
      "CRISPR U2OS 96\n"
     ]
    }
   ],
   "source": [
    "## Calc Eq_score data for real data\n",
    "folder_name = \"data\"\n",
    "for modality_1_perturbation in df.Metadata_experiment_type.unique():\n",
    "    for cell in df.Metadata_cell_line.unique():\n",
    "        for modality_1_timepoint in df.query(f'Metadata_cell_line == \"{cell}\" & Metadata_experiment_type == \"{modality_1_perturbation}\"').Metadata_timepoint.unique():\n",
    "            print(modality_1_perturbation, cell, modality_1_timepoint)\n",
    "            cell_line = cell\n",
    "            comp_time = modality_1_timepoint\n",
    "            comp_mod = modality_1_perturbation\n",
    "            comp_cond_query = f\"Metadata_experiment_type == '{comp_mod}' \\\n",
    "                        & Metadata_cell_line == '{cell_line}' \\\n",
    "                        & Metadata_timepoint == {comp_time} \\\n",
    "                        & Metadata_experiment_condition == 'Standard'\"\n",
    "            modality_1_df = df.query(comp_cond_query)\n",
    "            if modality_1_perturbation == 'Compound':\n",
    "                reference_col = 'Metadata_pert_iname'\n",
    "            else:\n",
    "                reference_col = 'Metadata_broad_sample'\n",
    "            # Log transform CP features\n",
    "            modality_1_df = pd.concat([ut.get_metadata(modality_1_df), ut.get_featuredata(modality_1_df).applymap(ut.log_transform)], axis=1)\n",
    "            # Calculate Eq. scores\n",
    "            comp_comp_eq_df, comp_comp_sse_df, q2_df = ut.calc_eq_score_df_with_cv_optimized(modality_1_df, modality_1_df, reference_col=reference_col)\n",
    "            eq_filename = f'{modality_1_perturbation}_with_{modality_1_perturbation}_eq_cv_{cell}_{modality_1_timepoint}'\n",
    "            sse_filename = f'{modality_1_perturbation}_with_{modality_1_perturbation}_sse_cv_{cell}_{modality_1_timepoint}'\n",
    "            q2_filename = f'{modality_1_perturbation}_with_{modality_1_perturbation}_q2_cv_{cell}_{modality_1_timepoint}'\n",
    "            comp_comp_eq_df.to_parquet(f\"./{folder_name}/{eq_filename}.parquet.gzip\")\n",
    "            comp_comp_sse_df.to_parquet(f\"./{folder_name}/{sse_filename}.parquet.gzip\")\n",
    "            q2_df.to_parquet(f\"./{folder_name}/{q2_filename}.parquet.gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compound A549 48\n",
      "Compound A549 24\n",
      "Compound U2OS 24\n",
      "Compound U2OS 48\n"
     ]
    }
   ],
   "source": [
    "## Calc Eq_scores for random data\n",
    "folder_name = \"data\"\n",
    "for modality_1_perturbation in ['Compound']: ## Only for Compound is enough\n",
    "    for cell in rand_df.Metadata_cell_line.unique():\n",
    "        for modality_1_timepoint in rand_df.query(f'Metadata_cell_line == \"{cell}\" & Metadata_experiment_type == \"{modality_1_perturbation}\"').Metadata_timepoint.unique():\n",
    "            print(modality_1_perturbation, cell, modality_1_timepoint)\n",
    "            cell_line = cell\n",
    "            comp_time = modality_1_timepoint\n",
    "            comp_mod = modality_1_perturbation\n",
    "            comp_cond_query = f\"Metadata_experiment_type == '{comp_mod}' \\\n",
    "                        & Metadata_cell_line == '{cell_line}' \\\n",
    "                        & Metadata_timepoint == {comp_time} \\\n",
    "                        & Metadata_experiment_condition == 'Standard'\"\n",
    "            modality_1_df = rand_df.query(comp_cond_query)\n",
    "            if modality_1_perturbation == 'Compound':\n",
    "                reference_col = 'Metadata_pert_iname'\n",
    "            else:\n",
    "                reference_col = 'Metadata_broad_sample'\n",
    "            # Log transform CP features\n",
    "            modality_1_df = pd.concat([ut.get_metadata(modality_1_df), ut.get_featuredata(modality_1_df).applymap(ut.log_transform)], axis=1)\n",
    "            # Calculate Eq. scores\n",
    "            comp_comp_eq_df, comp_comp_sse_df, q2_df = ut.calc_eq_score_df_with_cv_optimized(modality_1_df, modality_1_df, reference_col=reference_col)\n",
    "            eq_filename = f'{modality_1_perturbation}_with_{modality_1_perturbation}_eq_cv_{cell}_{modality_1_timepoint}_random'\n",
    "            sse_filename = f'{modality_1_perturbation}_with_{modality_1_perturbation}_sse_cv_{cell}_{modality_1_timepoint}_random'\n",
    "            q2_filename = f'{modality_1_perturbation}_with_{modality_1_perturbation}_q2_cv_{cell}_{modality_1_timepoint}_random'\n",
    "            comp_comp_eq_df.to_parquet(f\"./{folder_name}/{eq_filename}.parquet.gzip\")\n",
    "            comp_comp_sse_df.to_parquet(f\"./{folder_name}/{sse_filename}.parquet.gzip\")\n",
    "            q2_df.to_parquet(f\"./{folder_name}/{q2_filename}.parquet.gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
